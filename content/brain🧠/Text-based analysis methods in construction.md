---
Create_time: 2024-03-31 14:54
aliases: 
Unsolved: 
annotation-target:
---

---
[Cite :: [[@baekCriticalReviewTextbased2021a]] ]
[Last_modified : : `$= dv.current().file.mtime`.]


---
##### [notes ::  

## preprocessing
some studies manually developed a construction domain-specific lexicon and ontology to improve the performance of the TM model

## feature generation
 encoding raw textual data into feature-based representation
 Vector space model (VSM), which transforms text data as vectors in a matrix form, was dominant for feature generation. Vector values of features contain information about corresponding terms such as term frequency (TF)

 Parsing
 TF:   Identified keywords from a set of documents for information retrieval and text classification based on frequency.
 TF-IDF
 C-value approach ([C-value Approach to multi-word Automatic Term Recognition (ATR) | T/DG Blog - Digital Thoughts (thedigitalgroup.com)](https://blog.thedigitalgroup.com/c-value-approach-to-multi-word-automatic-term-recognition-atr))
  The Word2Vec, which is a neural network model proposed by Mikolov et al. [[108](https://www.sciencedirect.com/science/article/pii/S0926580521003666?via%3Dihub#bb0540)], captures semantic similarity by considering surrounding terms and embedding them at high [dimensional vector](https://www.sciencedirect.com/topics/engineering/dimensional-vector "Learn more about dimensional vector from ScienceDirect's AI-generated Topic Pages") space
## knowledge mining
 information retrieval (IR), information extraction (IE), text classification (TC)
 [[Deontic logic]] :   Developed semantic multilabel text classification model
 [[First order logic]] : Developed pattern-matching-based IE rules based on a pre-established ontology and first-order logic using semantic mapping rules and conflict resolution rules
 [[Rule-based attribute detection]]:   Analyzed syntactic occurrence patterns of the keywords, mainly considering the distance of the keywords in a sentence and the POS of each keyword
 [[Conceptual dependency theory]]: The theory involves primitives, states, and dependencies to construct conceptual dependency graphs from English sentences, enabling the representation of actions, mental information transfers, attention focus, and more.
 [[Frequent Patterns (FP)-growth method]] :  Created a FP-tree data structure by counting the frequency of word pairs in a paragraph
 [[IF-THEN logic]] : 
[[Ensemble model]] :  [[ensemble classifier]] by stacking the ripple down rules (RIDOR), K-Star, and radial basis function (RBF) networks
				  Classified the cause of construction accidents based on an ensemble model with five baseline models, namely, SVM, linear regression (LR), KNN, DT and NB.
[[Convolutional neural network]] : Developed DL-based short text classification model using CNN
[[Bi-LSTM]] : Applied Bi-LSTM architecture for NER and TC
		Developed a hybrid model using Bi-LSTM and CRF
[[LDA]] :  Performed [[topic modeling]] using various documents

[[Self-attention mechanism]] :   Developed text classification model using BERT
]


---

[永久筆記 :: ]
	
- [x]

- [ ] 總之

- [ ] 意義

- [ ] 延伸

- [ ] 反之


---
#### 歸檔 
	-  [ ]
	-  #


---
#### 索引
