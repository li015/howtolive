---
Create_time: 2024-01-25 09:51
aliases: 
Unsolved: 
annotation-target:
---

---
[Cite ::  ]
[Last_modified : : `$= dv.current().file.mtime`.]


---
##### [notes ::  

[[Prompt]]沒有一定正確的寫法標準

不同的 LLM 模型，表現不一樣、Prompt 也有差異

有幻覺現象 (Hallucination) 可能會唬爛
Using a lot of prompt engineering, we can set behavioral guidelines and get good tool selection (in the case of agents), but it is still non-deterministic generation. With these chatbots, there is no guarantee of functionality, and slip-ups are common.


API 是 Stateless 無狀態的: 每次呼叫 API需要傳全部對話紀錄，否則 LLM 不會記得你之前講了啥

Token 有長度限制 (Context Window)

知識實時性 (有 cut-off date)

[[RAG query decomposition]]

[[Conversational Memory]]

 ReAct is that our LLMs should go through "thinking loops" where they **Re**ason and **Act**.
 AI developers build agent tooling with [LangChain](https://www.pinecone.io/learn/series/langchain/), but there are alternatives. [Llama-index](https://github.com/jerryjliu/llama_index) has recently introduced its agent support, [Haystack](https://github.com/deepset-ai/haystack/) has supported agents for some time, and [OpenAI Function Calling](https://www.youtube.com/watch?v=dgV4WFisK5Y) can be spun into an agent-style framework with some additional effort.

[[Guardrail]]


[[Agent method]]
]

---

[永久筆記 :: ]
	
- [x]

- [ ] 總之

- [ ] 意義

- [ ] 延伸

- [ ] 反之


---
#### 歸檔 
	-  [ ]
	-  #


---
#### 索引
